{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94688348-7ab5-414f-867c-183c5e0000e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('code/')\n",
    "\n",
    "from preprocess import preprocess\n",
    "from preprocess import load_config\n",
    "from train import train_classifier\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5937599d-3c30-48be-8734-e5b75a88b4cb",
   "metadata": {},
   "source": [
    "# Initialise Configuration \n",
    "\n",
    "<p>A configuration file is necessary to set hyperparameters and variables for preprocessing and training. Find the description of each key in the following frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26dc5506-4a91-43a1-9abf-7fa547fd9d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'suppliment_testing': 0, # amount of samples to be taken from training and added to testing \n",
    "                                   # Necessary if not all labels present in testing \n",
    "                                   # A script that balances the dataset would be better\n",
    "          \n",
    "          'taglist': {'1-RAPPORT'       : 0,\n",
    "                      '2-NEGOTIATE'     : 1,\n",
    "                      '3-EMOTION'       : 2,\n",
    "                      '4-LOGIC'         : 3,\n",
    "                      '5-AUTHORITY'     : 4,\n",
    "                      '6-SOCIAL'        : 5,\n",
    "                      '7-PRESSURE'      : 6,\n",
    "                      '8-NO-PERSUASION' : 7,\n",
    "                      'NO-TAG'          : 8},\n",
    "          \n",
    "         'testing_data': {'conf_threshold' : 0.5,                 # Confidence threshold to allow testing sample \n",
    "                          'output_path'    : 'data/dataloaders/', # output path if generating dataloader\n",
    "                          'path'           : 'data/post_processed/testing_data.jsonl'}, # path to jsonlist file\n",
    "          \n",
    "         'training_data': {'conf_threshold': 0.5,\n",
    "                           'output_path'   : 'data/dataloaders/',\n",
    "                           'path'          : 'data/post_processed/training_data.jsonl'},\n",
    "          \n",
    "         'vectoriser_config': {'type'        : 1 ,         # 1 counts 2 tfidf\n",
    "                               'lowercase'   : True,       # lowercase tokens\n",
    "                               'ngram_range' : '(1,1)',    # ngram range (1,1) is only unigrams (1, 2) is uni and bigrams \n",
    "                               'stop_words'  : 'english'}, # remove stopwords from language\n",
    "          \n",
    "         'model_config': {'type'        : 2,         # 1 - MLP 2 - SVM\n",
    "                          'onevsrest'   : True,     # wrap in onevsrest\n",
    "                          'output_path' : 'models/', # output folder for model\n",
    "                          'max_iter'    : 400}}      # max iterations in training \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba8a77-414f-4874-af17-1e617c6e63e8",
   "metadata": {},
   "source": [
    "# Preprocess Training Data \n",
    "\n",
    "We can now preprocess the data using the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6857d0b-94c7-4d8e-acb4-16c741d64ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training: 7755\n",
      "Total Testing: 1694\n"
     ]
    }
   ],
   "source": [
    "config, vectorizer_name, vectorizer, train_x, train_y, test_x, test_y = preprocess(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee283202-9e79-4482-9e29-118509266615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_tags_counts(counts):\n",
    "    \n",
    "    x = list(counts.keys())[:-1]\n",
    "    y = list(counts.values())[:-1]\n",
    "    \n",
    "    plt.bar(x,y)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.setp(labels, rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "def count_training_tags(config, train_y):\n",
    "    idx2tag = { idx : tag for tag, idx in config.get('taglist').items()}\n",
    "    counts = {tag : 0 for tag in idx2tag.values()}\n",
    "\n",
    "    for tagidx in train_y:\n",
    "        counts[idx2tag[tagidx]] += 1\n",
    "        \n",
    "    config['training_dist'] = counts\n",
    "    \n",
    "    show_tags_counts(counts)\n",
    "    return idx2tag, counts, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b53c1a9-a180-406f-b767-e0919a3e2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx2tag, counts, config = count_training_tags(config, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171843ed-ede2-4180-aa15-1139e87f22c2",
   "metadata": {},
   "source": [
    "# Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33291c0e-226f-48a7-9087-1be86b82b897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:   25.5s remaining:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   41.2s finished\n"
     ]
    }
   ],
   "source": [
    "clf, test_x, test_y = train_classifier(config, vectorizer_name=vectorizer_name,vectorizer=vectorizer,\n",
    "                            train_x=train_x, train_y=train_y, test_x=test_x, test_y=test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c34b4-199b-41ab-83a3-155b98e02642",
   "metadata": {},
   "source": [
    "# Evaluate Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ae88cb7-18ee-4074-8d78-c30f6308e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.train import evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "from code.train import output_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36ffccf5-c71e-423c-b5eb-6f93de8be052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(trained_model, test_x, test_y, config, verbose=None):\n",
    "\n",
    "    idx2tag = {idx : tag for tag, idx in config.get('taglist').items()}\n",
    "    \n",
    "    try:\n",
    "        labels = list(sorted(set([idx2tag[i] for i in test_y])))\n",
    "    except:\n",
    "        labels = list(idx2tag.values())\n",
    "    \n",
    "    \n",
    "    preds = trained_model.predict(test_x)\n",
    "    report = classification_report(preds, test_y, target_names = labels,zero_division=True, output_dict=True)\n",
    "    \n",
    "    if verbose:\n",
    "        text = classification_report(preds, test_y, target_names = labels,zero_division=True)\n",
    "        print(text)\n",
    "        \n",
    "    config['classification_report'] = report\n",
    "    config['time'] = datetime.now().strftime('%d-%m-%Y %H:%M')\n",
    "\n",
    "    if config['model_config'].get('output_path'):\n",
    "        output_eval(trained_model, config)\n",
    "    \n",
    "    return config, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33ee600d-15ca-404c-ae63-92998453e17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      1-RAPPORT       0.82      0.83      0.83      1244\n",
      "    2-NEGOTIATE       0.31      0.98      0.48       170\n",
      "      3-EMOTION       0.18      0.94      0.30       106\n",
      "        4-LOGIC       0.11      0.88      0.19        32\n",
      "    5-AUTHORITY       0.14      0.85      0.25        26\n",
      "       6-SOCIAL       0.00      1.00      0.00         0\n",
      "     7-PRESSURE       0.00      1.00      0.00         0\n",
      "8-NO-PERSUASION       0.55      0.89      0.68       838\n",
      "         NO-TAG       1.00      1.00      1.00         0\n",
      "\n",
      "      micro avg       0.48      0.87      0.62      2416\n",
      "      macro avg       0.35      0.93      0.41      2416\n",
      "   weighted avg       0.65      0.87      0.71      2416\n",
      "    samples avg       0.55      0.89      0.62      2416\n",
      "\n",
      "Outputting model to models/model_20_bow_unigrams_svm_True.pkl\n",
      "Outputting config to models/model_20_bow_unigrams_svm_True.yaml\n"
     ]
    }
   ],
   "source": [
    "report, text = evaluate(clf, test_x, test_y, config, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe911d-7852-4709-a93e-4405a6247659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
